{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "from src.model import XRDict\n",
    "from src.data import XRDictDataset, device, data_processing\n",
    "from src.train import train\n",
    "\n",
    "from src.vocab import Vocab\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab('./embeddings/vec_inuse.json')\n",
    "model = XRDict(ckpt_path='checkpoints/mlm_tlm_xnli15_1024.pth', vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = json.load(open('./data/train_bpe.json', 'r', encoding='utf-8'))\n",
    "train_data, valid_data, test_data = data_processing(bpe, model.dico.word2id, vocab.word2id)\n",
    "\n",
    "train_dataset = XRDictDataset(train_data)\n",
    "valid_dataset = XRDictDataset(valid_data)\n",
    "test_dataset = XRDictDataset(test_data)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, 1, (train_dataset, valid_dataset, train_dataset), optimizer, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_bpe = [d['definitions'] for d in bpe]\n",
    "n_w = len([w for w in ' '.join(sentences_bpe).split()])\n",
    "n_oov = len([w for w in ' '.join(sentences_bpe).split() if w not in model.dico.word2id])\n",
    "print('Number of out-of-vocab words: %s/%s' % (n_oov, n_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_bpe = [(('</s> %s </s>' % sent.strip()).split()) for sent in sentences_bpe]\n",
    "\n",
    "bs = len(sentences_bpe)\n",
    "slen = max([len(sent) for sent in sentences_bpe])\n",
    "\n",
    "word_ids = torch.LongTensor(slen, bs).fill_(model.params.pad_index).to(device)\n",
    "for i in range(len(sentences_bpe)):\n",
    "    sent = torch.LongTensor([model.dico.index(w) for w in sentences_bpe[i]])\n",
    "    word_ids[:len(sent), i] = sent\n",
    "\n",
    "lengths = torch.LongTensor([len(sent) for sent in sentences_bpe]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "score = model(x=word_ids, lengths=lengths, causal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6192930a0a42d1c215eff05850c42caaec721c2da4dc38a28e3689d1bbf37b44"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('XLM-R')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
